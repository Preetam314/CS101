{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Preetam314/CS101/blob/main/NLP_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install libraries (run in Colab). If you're running locally, you may not need installs.\n",
        "!pip install -q datasets transformers evaluate seqeval accelerate gradio scikit-learn matplotlib torch>=1.12.0\n",
        "!pip install -U transformers accelerate\n",
        "\n",
        "\n",
        "# GPU check (optional)\n",
        "import torch\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "id": "7STNVfSMjp7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9072de28-5aa6-4285-ce84-f3c03a54a754"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports and global config\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
        "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "id": "ATuL_Yz6jqce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 (New): Load multiple languages\n",
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "# 1. Load English data for training\n",
        "ds_en = load_dataset(\"amazon_reviews_multi\", \"en\")\n",
        "# Note: amazon_reviews_multi labels are 1-5 stars. We must make them binary (0, 1)\n",
        "# like amazon_polarity. We'll map 1,2 -> 0 (neg) and 4,5 -> 1 (pos). We'll discard 3.\n",
        "def process_data(dataset):\n",
        "    dataset = dataset.map(lambda x: {\"label\": 0 if x[\"stars\"] < 3 else (1 if x[\"stars\"] > 3 else -1)})\n",
        "    dataset = dataset.filter(lambda x: x[\"label\"] != -1)\n",
        "    return dataset\n",
        "\n",
        "ds_en = process_data(ds_en)\n",
        "\n",
        "# 2. Load other languages for *testing only*\n",
        "ds_de = process_data(load_dataset(\"amazon_reviews_multi\", \"de\", split=\"test\"))\n",
        "ds_fr = process_data(load_dataset(\"amazon_reviews_multi\", \"fr\", split=\"test\"))\n",
        "ds_ja = process_data(load_dataset(\"amazon_reviews_multi\", \"ja\", split=\"test\"))\n",
        "\n",
        "# 3. Create your final dataset dict\n",
        "# (Using smaller subsets for the demo, just like you did)\n",
        "train_dataset = ds_en['train'].shuffle(seed=42).select(range(20000))\n",
        "eval_dataset_en = ds_en['test'].shuffle(seed=42).select(range(2000)) # English test\n",
        "eval_dataset_de = ds_de.shuffle(seed=42).select(range(2000)) # German test\n",
        "eval_dataset_fr = ds_fr.shuffle(seed=42).select(range(2000)) # French test\n",
        "eval_dataset_ja = ds_ja.shuffle(seed=42).select(range(2000)) # Japanese test\n",
        "\n",
        "# Your main \"dataset\" for tokenization will be the English one\n",
        "dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'test': eval_dataset_en\n",
        "})\n",
        "\n",
        "# Keep the other test sets separate for now\n",
        "test_sets_other_langs = {\n",
        "    \"German\": eval_dataset_de,\n",
        "    \"French\": eval_dataset_fr,\n",
        "    \"Japanese\": eval_dataset_ja\n",
        "}\n"
      ],
      "metadata": {
        "id": "IIaNJFMOj3Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LxGYRSiFkg1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Light model selection + tokenizer setup (memory-friendly)\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Disable Weights & Biases tracking\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Smaller models to reduce RAM/VRAM\n",
        "model_name_mono = \"distilbert-base-uncased\"              # English only\n",
        "model_name_multi = \"distilbert-base-multilingual-cased\"  # Multilingual\n",
        "\n",
        "tokenizer_mono = AutoTokenizer.from_pretrained(model_name_mono)\n",
        "tokenizer_multi = AutoTokenizer.from_pretrained(model_name_multi)\n",
        "\n",
        "max_length = 256\n",
        "print(\"Tokenizers loaded successfully ✅\")\n"
      ],
      "metadata": {
        "id": "SmdVjLTAksIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 (Corrected): Tokenize the correct columns\n",
        "from datasets import DatasetDict\n",
        "\n",
        "# --- Limit dataset size for Colab (adjust numbers if you have more RAM) ---\n",
        "# This part is fine, but we'll re-run it on the 'dataset' from Cell 3\n",
        "dataset = DatasetDict({\n",
        "    \"train\": dataset[\"train\"].shuffle(seed=42).select(range(2000)),\n",
        "    \"test\": dataset[\"test\"].shuffle(seed=42).select(range(500))\n",
        "})\n",
        "\n",
        "# [FIX] Tokenize 'review_body' instead of 'content'\n",
        "def tokenize_mono(examples):\n",
        "    return tokenizer_mono(examples[\"review_body\"], truncation=True, max_length=max_length)\n",
        "\n",
        "def tokenize_multi(examples):\n",
        "    return tokenizer_multi(examples[\"review_body\"], truncation=True, max_length=max_length)\n",
        "\n",
        "print(\"Tokenizing English dataset for training/evaluation...\")\n",
        "tokenized_mono = dataset.map(tokenize_mono, batched=True)\n",
        "tokenized_multi = dataset.map(tokenize_multi, batched=True)\n",
        "\n",
        "# [FIX] Remove columns from the *new* dataset\n",
        "# The original dataset has many columns, let's list them\n",
        "original_cols = dataset[\"train\"].column_names\n",
        "cols_to_remove = [c for c in original_cols if c not in [\"input_ids\", \"attention_mask\", \"label\"]]\n",
        "\n",
        "print(f\"Removing columns: {cols_to_remove}\")\n",
        "tokenized_mono = tokenized_mono.remove_columns(cols_to_remove)\n",
        "tokenized_multi = tokenized_multi.remove_columns(cols_to_remove)\n",
        "\n",
        "print(\"✅ Tokenization done\")\n",
        "print(\"Columns:\", tokenized_mono[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "Zpq2dcMokwZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 (final, tested on transformers 4.40+)\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np, torch, os\n",
        "\n",
        "def make_model_and_trainer(model_name, tokenized_dataset, tokenizer, output_dir,\n",
        "                           epochs=1, batch_size=8, learning_rate=2e-5):\n",
        "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "    num_labels = 2\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name, num_labels=num_labels\n",
        "    ).to(device)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        eval_strategy=\"epoch\", # Changed from evaluation_strategy\n",
        "        save_strategy=\"no\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        learning_rate=learning_rate,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=0.01,\n",
        "        gradient_checkpointing=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        report_to=\"none\",          # disable wandb/tensorboard\n",
        "        logging_dir=f\"{output_dir}/logs\"\n",
        "    )\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "    def compute_metrics(pred):\n",
        "        labels = pred.label_ids\n",
        "        preds = np.argmax(pred.predictions, axis=1)\n",
        "        return {\n",
        "            \"accuracy\": accuracy_score(labels, preds),\n",
        "            \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
        "        }\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=tokenized_dataset[\"train\"],\n",
        "        eval_dataset=tokenized_dataset[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    return model, trainer"
      ],
      "metadata": {
        "id": "l0XqKkeHkz7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mono_out = \"runs/distilbert_fastdemo\"\n",
        "\n",
        "model_mono, trainer_mono = make_model_and_trainer(\n",
        "    model_name_mono, tokenized_mono, tokenizer_mono,\n",
        "    output_dir=mono_out, epochs=0.5, batch_size=8\n",
        ")\n",
        "\n",
        "# Override trainer args for speed\n",
        "trainer_mono.args.evaluation_strategy = \"no\"\n",
        "trainer_mono.args.logging_steps = 200\n",
        "trainer_mono.args.save_strategy = \"no\"\n",
        "trainer_mono.args.gradient_accumulation_steps = 4\n",
        "trainer_mono.args.per_device_train_batch_size = 2\n",
        "trainer_mono.args.per_device_eval_batch_size = 2\n",
        "\n",
        "trainer_mono.train()\n",
        "print(\"✅ Training finished (fast demo mode)\")\n",
        "\n",
        "\n",
        "eval_mono = trainer_mono.evaluate()\n",
        "print(\"Monolingual eval:\", eval_mono)"
      ],
      "metadata": {
        "id": "cyAt2YS6k7LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Train multilingual model (XLM-R) on same English training data\n",
        "multi_out = \"runs/xlm_roberta_multi_demo\"\n",
        "model_multi, trainer_multi = make_model_and_trainer(model_name_multi, tokenized_multi, tokenizer_multi, multi_out, epochs=0.5, batch_size=16, learning_rate=2e-5)\n",
        "\n",
        "trainer_multi.args.evaluation_strategy = \"no\"\n",
        "trainer_multi.args.logging_steps = 200\n",
        "trainer_multi.args.save_strategy = \"no\"\n",
        "trainer_multi.args.gradient_accumulation_steps = 4\n",
        "trainer_multi.args.per_device_train_batch_size = 2\n",
        "trainer_multi.args.per_device_eval_batch_size = 2\n",
        "\n",
        "trainer_multi.train()\n",
        "eval_multi = trainer_multi.evaluate()\n",
        "print(\"Multilingual eval:\", eval_multi)\n"
      ],
      "metadata": {
        "id": "ywEB_oU9m4kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10 (Corrected): Evaluation loop with correct column names\n",
        "\n",
        "# [FIX] Make sure this function is defined *before* you call it.\n",
        "# You can move this function to Cell 7 or run it here.\n",
        "def get_preds_and_report(trainer, dataset, tokenizer):\n",
        "    preds_output = trainer.predict(dataset)\n",
        "    preds = np.argmax(preds_output.predictions, axis=1)\n",
        "    labels = preds_output.label_ids\n",
        "    print(classification_report(labels, preds, digits=4))\n",
        "    return preds, labels\n",
        "\n",
        "results = {}\n",
        "\n",
        "# 1. Evaluate on English (like you already did)\n",
        "print(\"--- Monolingual model on English ---\")\n",
        "mono_preds_en, mono_labels_en = get_preds_and_report(trainer_mono, tokenized_mono['test'], tokenizer_mono)\n",
        "results[\"Mono (en)\"] = f1_score(mono_labels_en, mono_preds_en, average=\"weighted\")\n",
        "\n",
        "print(\"--- Multilingual model on English ---\")\n",
        "multi_preds_en, multi_labels_en = get_preds_and_report(trainer_multi, tokenized_multi['test'], tokenizer_multi)\n",
        "results[\"Multi (en)\"] = f1_score(multi_labels_en, multi_preds_en, average=\"weighted\")\n",
        "\n",
        "\n",
        "# 2. Now, evaluate on the other languages (ZERO-SHOT)\n",
        "for lang, test_data in test_sets_other_langs.items():\n",
        "    print(f\"--- Evaluating on {lang} (Zero-Shot) ---\")\n",
        "\n",
        "    # [FIX] Tokenize and remove the *correct* columns for the test sets\n",
        "    test_cols = test_data.column_names\n",
        "    cols_to_remove_test = [c for c in test_cols if c not in [\"input_ids\", \"attention_mask\", \"label\"]]\n",
        "\n",
        "    # Tokenize this language's test set (using the *fixed* functions from Cell 6)\n",
        "    tok_mono_lang = test_data.map(tokenize_mono, batched=True).remove_columns(cols_to_remove_test)\n",
        "    tok_multi_lang = test_data.map(tokenize_multi, batched=True).remove_columns(cols_to_remove_test)\n",
        "\n",
        "    # A) Evaluate Monolingual model (should fail badly)\n",
        "    print(f\"Monolingual model ({lang}):\")\n",
        "    mono_preds, mono_labels = get_preds_and_report(trainer_mono, tok_mono_lang, tokenizer_mono)\n",
        "    results[f\"Mono ({lang})\"] = f1_score(mono_labels, mono_preds, average=\"weighted\")\n",
        "\n",
        "    # B) Evaluate Multilingual model (should do much better)\n",
        "    print(f\"Multilingual model ({lang}):\")\n",
        "    multi_preds, multi_labels = get_preds_and_report(trainer_multi, tok_multi_lang, tokenizer_multi)\n",
        "    results[f\"Multi ({lang})\"] = f1_score(multi_labels, multi_preds, average=\"weighted\")\n",
        "\n",
        "print(\"--- Summary F1 Scores ---\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "oNb6lGZq6Fvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11 (Corrected): Visualize the *actual* cross-lingual results\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Create a DataFrame from the 'results' dict for easy plotting\n",
        "df_results = pd.DataFrame.from_dict(results, orient='index', columns=['F1-Score'])\n",
        "df_results = df_results.reset_index().rename(columns={'index': 'Test Case'})\n",
        "\n",
        "# Separate by model and language\n",
        "df_results[['Model', 'Language']] = df_results['Test Case'].str.extract(r'(Mono|Multi) \\((.*)\\)')\n",
        "\n",
        "# 2. Create the bar chart comparing language performance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    x='Language',\n",
        "    y='F1-Score',\n",
        "    hue='Model',\n",
        "    data=df_results,\n",
        "    order=['en', 'de', 'fr', 'ja'] # Specify order\n",
        ")\n",
        "plt.title('Zero-Shot Cross-Lingual Performance (Trained on English)')\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('F1-Score (Weighted)')\n",
        "plt.xlabel('Test Language')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.savefig(\"cross_lingual_performance.png\")\n",
        "print(\"Saved cross-lingual performance plot to cross_lingual_performance.png\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 3. Confusion Matrix\n",
        "# [FIX] This matrix will only be for the *last* language in the loop (Japanese).\n",
        "# Let's plot the matrix for the *English* test set as a baseline.\n",
        "print(\"\\nMultilingual Model Confusion Matrix (on English Test Set)\")\n",
        "cm_multi_en = confusion_matrix(multi_labels_en, multi_preds_en)\n",
        "disp = ConfusionMatrixDisplay(cm_multi_en, display_labels=[\"neg\",\"pos\"])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix - Multilingual Model (on English)\")\n",
        "plt.savefig(\"confusion_matrix_multi_en.png\")\n",
        "print(\"Saved confusion matrix to confusion_matrix_multi_en.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j7QZYmEO6Huk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Show examples where the models disagree\n",
        "def decode_input(tokenizer, tokenized_batch, idx):\n",
        "    # reconstruct input text if original text removed\n",
        "    # if we have no original text column, we can't easily decode; show tokens instead\n",
        "    input_ids = tokenized_batch['input_ids'][idx]\n",
        "    return tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "\n",
        "# We'll compare predictions on the first 200 test examples\n",
        "disagreements = []\n",
        "for i in range(min(200, len(tokenized_mono['test']))):\n",
        "    # get predictions by running models directly in eval mode\n",
        "    with torch.no_grad():\n",
        "        # mono\n",
        "        mi = {k: torch.tensor([v[i]]).to(device) for k,v in tokenized_mono['test'][i].items() if k in ['input_ids','attention_mask','token_type_ids'] or k in ['input_ids','attention_mask']}\n",
        "        mo_logits = model_mono(**{k:v for k,v in mi.items() if k in model_mono.forward.__code__.co_varnames})\n",
        "        m_pred = int(torch.argmax(mo_logits.logits, dim=1).cpu().numpy())\n",
        "\n",
        "        # multi\n",
        "        xi = {k: torch.tensor([v[i]]).to(device) for k,v in tokenized_multi['test'][i].items() if k in ['input_ids','attention_mask']}\n",
        "        xo_logits = model_multi(**{k:v for k,v in xi.items() if k in model_multi.forward.__code__.co_varnames})\n",
        "        x_pred = int(torch.argmax(xo_logits.logits, dim=1).cpu().numpy())\n",
        "\n",
        "    true_label = tokenized_mono['test'][i]['label']\n",
        "    if m_pred != x_pred:\n",
        "        text = decode_input(tokenizer_mono, tokenized_mono['test'], i)\n",
        "        disagreements.append((i, text, true_label, m_pred, x_pred))\n",
        "        if len(disagreements) >= 10:\n",
        "            break\n",
        "\n",
        "for d in disagreements:\n",
        "    idx, text, true, mono_p, multi_p = d\n",
        "    print(f\"Idx {idx} | True: {true} | Mono: {mono_p} | Multi: {multi_p}\\n{text}\\n---\\n\")\n"
      ],
      "metadata": {
        "id": "zXPH1vJm6Jf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Gradio demo to try both models interactively\n",
        "import gradio as gr\n",
        "\n",
        "# load tokenizer and models on CPU for demo if GPU not available\n",
        "mono_pipeline_tokenizer = tokenizer_mono\n",
        "multi_pipeline_tokenizer = tokenizer_multi\n",
        "model_mono.eval()\n",
        "model_multi.eval()\n",
        "\n",
        "def predict_both(text):\n",
        "    # mono\n",
        "    tok_m = mono_pipeline_tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\", max_length=max_length).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits_m = model_mono(**tok_m).logits\n",
        "    pred_m = int(torch.argmax(logits_m, dim=1).cpu().numpy())\n",
        "    # multi\n",
        "    tok_x = multi_pipeline_tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\", max_length=max_length).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits_x = model_multi(**tok_x).logits\n",
        "    pred_x = int(torch.argmax(logits_x, dim=1).cpu().numpy())\n",
        "    label_map = {0:\"Negative\", 1:\"Positive\"}\n",
        "    return label_map[pred_m], label_map[pred_x]\n",
        "\n",
        "iface = gr.Interface(fn=predict_both,\n",
        "                     inputs=gr.Textbox(lines=4, placeholder=\"Enter review here...\"),\n",
        "                     outputs=[gr.Label(num_top_classes=1, label=\"Monolingual (BERT)\"),\n",
        "                              gr.Label(num_top_classes=1, label=\"Multilingual (XLM-R)\")],\n",
        "                     title=\"Monolingual vs Multilingual Sentiment Demo\",\n",
        "                     description=\"Enter text (any language). Models trained on English demo subset; multilingual model may generalize better to other languages.\")\n",
        "iface.launch(share=False)\n"
      ],
      "metadata": {
        "id": "XQDgGCXz6Lz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Save the fine-tuned models & tokenizers locally\n",
        "save_dir_mono = \"saved_models/bert_mono\"\n",
        "save_dir_multi = \"saved_models/xlm_roberta_multi\"\n",
        "os.makedirs(save_dir_mono, exist_ok=True)\n",
        "os.makedirs(save_dir_multi, exist_ok=True)\n",
        "\n",
        "model_mono.save_pretrained(save_dir_mono)\n",
        "tokenizer_mono.save_pretrained(save_dir_mono)\n",
        "\n",
        "model_multi.save_pretrained(save_dir_multi)\n",
        "tokenizer_multi.save_pretrained(save_dir_multi)\n",
        "\n",
        "print(\"Saved models to:\", save_dir_mono, save_dir_multi)\n"
      ],
      "metadata": {
        "id": "re8dO1fK6N6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t5dCNFQq6P7f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}